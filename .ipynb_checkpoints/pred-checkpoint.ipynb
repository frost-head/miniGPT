{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from Model import model, modelArguments\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "import triton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_519698/2760450671.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('./checkpoints/model_weightsBPE.pth')\n"
     ]
    }
   ],
   "source": [
    "fmodel = model(modelArguments)\n",
    "\n",
    "state_dict = torch.load('./checkpoints/model_weightsBPE.pth')\n",
    "new_state_dict = {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n",
    "fmodel.load_state_dict(new_state_dict, strict=False)\n",
    "\n",
    "fmodel = fmodel.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"large_tokenizer.json\")\n",
    "\n",
    "\n",
    "def tokenize(text, second = False):\n",
    "    ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    ids1 = ids\n",
    "    ids1 = torch.tensor(ids1, dtype=torch.int16)\n",
    "    \n",
    "    # # Pad or truncate the sequence to tholtae max_seq_length\n",
    "    # if ids1.size(0) < modelArguments.max_seq_len:\n",
    "    #     padding_length = modelArguments.max_seq_len - ids1.size(0)\n",
    "    #     ids1 = torch.cat([ids1, torch.zeros(padding_length, dtype=torch.int16)])\n",
    "        \n",
    "    # elif ids1.size(0) >= modelArguments.max_seq_len:\n",
    "    #     ids1 = ids1[:modelArguments.max_seq_len]\n",
    "    #     ids1[-1] = 2\n",
    "    return ids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_token(x):\n",
    "    s = ''\n",
    "    for i in x[0]:\n",
    "        # j = torch.argmax(i)\n",
    "        s += tokenizer.decode(i)\n",
    "\n",
    "    return s\n",
    "\n",
    "def id_to_token_M(x):\n",
    "    s = ''\n",
    "    for i in x[0]:\n",
    "        j = torch.argmax(i)\n",
    "        s += tokenizer.decode(j)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model(\n",
       "  (shared_emb): shared_emb()\n",
       "  (enc_layers): ModuleList(\n",
       "    (0-9): 10 x EncoderBlock(\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): FlashAttention(\n",
       "        (q_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (k_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (v_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (out_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sentence\n",
    "\n",
    "sentences = [\"\"\"Summarize the given paragraph \\n Ayush Sharma, also known as Frost Head, is a dynamic and forward-thinking individual with a deep passion for technology. With a multifaceted expertise that spans deep learning, AI, and web development, Ayush combines technical prowess, creative thinking, and problem-solving finesse. Born in Mandi, Himachal Pradesh, India, Ayush has been immersed in the world of programming since a young age, honing his skills and staying at the forefront of technological advancements. \\n\\n\"\"\",\n",
    "            \n",
    "            \"\"\"Given the paragraph where is Ayush Sharma born \\n Ayush Sharma, also known as Frost Head, is a dynamic and forward-thinking individual with a deep passion for technology. With a multifaceted expertise that spans deep learning, AI, and web development, Ayush combines technical prowess, creative thinking, and problem-solving finesse. Born in Mandi, Himachal Pradesh, India, Ayush has been immersed in the world of programming since a young age, honing his skills and staying at the forefront \\n\\n\"\"\",\n",
    "             \n",
    "             \"\"\"Given the paragraph what are Ayush Sharma's skills \\n Ayush Sharma, also known as Frost Head, is a dynamic and forward-thinking individual with a deep passion for technology. With a multifaceted expertise that spans deep learning, AI, and web development, Ayush combines technical prowess, creative thinking, and problem-solving finesse. Born in Mandi, Himachal Pradesh, India, Ayush has been immersed in the world of programming since a young age, honing his skills and staying at the \\n\\n\"\"\"\n",
    "            ]\n",
    "\n",
    "\n",
    "generated_ids = []\n",
    "for i in sentences:\n",
    "    generated_id  = torch.tensor(tokenizer.encode(i)).to(torch.long).to('cuda').unsqueeze(0)\n",
    "    generated_ids.append(generated_id)\n",
    "\n",
    "\n",
    "\n",
    "generated_ids = torch.cat(generated_ids)\n",
    "\n",
    "\n",
    "# generated_ids = torch.tensor(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 110])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 110])\n",
      "Generated text: Summarize the given paragraph \n",
      " Ayush Sharma, also known as Frost Head, is a dynamic and forward-thinking individual with a deep passion for technology. With a multifaceted expertise that spans deep learning, AI, and web development, Ayush combines technical prowess, creative thinking, and problem-solving finesse. Born in Mandi, Himachal Pradesh, India, Ayush has been immersed in the world of programming since a young age, honing his skills and staying at the forefront of technological advancements. \n",
      "\n",
      "The Indian-language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language[EOS]\n",
      "time taken  5555.359601974487\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(generated_ids.shape)\n",
    "# print(generated_ids)\n",
    "# generated_ids = generated_id.repeat(4, 1)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for _ in range(modelArguments.max_seq_len-generated_ids.size(1)):  # Generate up to 20 tokens\n",
    "    with torch.no_grad():\n",
    "        logits = fmodel(generated_ids)  # Pass the current sequence to the model\n",
    "        next_token_logits = logits[:, -1, :]  # Get logits for the last token\n",
    "\n",
    "\n",
    "    # Predict the next token (greedy decoding)\n",
    "    next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(1)  # Shape: [1, 1]\n",
    "\n",
    "    # Append the predicted token to the sequence\n",
    "    generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
    "\n",
    "    # Stop if EOS token is predicted\n",
    "    # if next_token_id.item() == 2:\n",
    "    #     print(\"eos\")\n",
    "    #     break\n",
    "\n",
    "t1 = time.time()\n",
    "# Decode the generated sequence\n",
    "output_text = tokenizer.decode(generated_ids[0])\n",
    "print(\"Generated text:\", output_text)\n",
    "t = (t1-t0)*1000\n",
    "print(\"time taken \", t)\n",
    "# generated_ids = generated_id.repeat(2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Summarize the given paragraph \n",
      " Ayush Sharma, also known as Frost Head, is a dynamic and forward-thinking individual with a deep passion for technology. With a multifaceted expertise that spans deep learning, AI, and web development, Ayush combines technical prowess, creative thinking, and problem-solving finesse. Born in Mandi, Himachal Pradesh, India, Ayush has been immersed in the world of programming since a young age, honing his skills and staying at the forefront of technological advancements. \n",
      "\n",
      "The Indian-language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language language[EOS]\n"
     ]
    }
   ],
   "source": [
    "output_text = tokenizer.decode(generated_ids[0])\n",
    "print(\"Generated text:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Given the paragraph where is Ayush Sharma born \n",
      " Ayush Sharma, also known as Frost Head, is a dynamic and forward-thinking individual with a deep passion for technology. With a multifaceted expertise that spans deep learning, AI, and web development, Ayush combines technical prowess, creative thinking, and problem-solving finesse. Born in Mandi, Himachal Pradesh, India, Ayush has been immersed in the world of programming since a young age, honing his skills and staying at the forefront \n",
      "\n",
      "The Ayush Sharma is a dynamic and dynamic company that has gained significant attention in the field of technology, technology, and technology His approach to innovation has led to a significant shift in the field of technology, and he has been a part of the Indian community\n",
      "The Ayush Sharma is a renowned leader in the field of technology, and he has been instrumental in shaping the future of the field of technology His dedication to innovation and innovation has led to a significant transformation in the field of technology\n",
      "The Ayush Sharma is a testament to the importance of innovation and innovation in the field of technology, and he has gained immense recognition and recognition for his dedication to the field of technology[EOS][EOS][EOS][EOS][EOS][EOS][EOS][EOS][EOS]\n"
     ]
    }
   ],
   "source": [
    "output_text = tokenizer.decode(generated_ids[1])\n",
    "print(\"Generated text:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Given the paragraph what are Ayush Sharma's skills \n",
      " Ayush Sharma, also known as Frost Head, is a dynamic and forward-thinking individual with a deep passion for technology. With a multifaceted expertise that spans deep learning, AI, and web development, Ayush combines technical prowess, creative thinking, and problem-solving finesse. Born in Mandi, Himachal Pradesh, India, Ayush has been immersed in the world of programming since a young age, honing his skills and staying at the \n",
      "\n",
      "The Indian Eye of Ayush Sharma is a powerful and powerful tool that can be used to enhance the overall experience of the Indian Eye of Medicine, and it is a powerful tool that can be used to enhance the overall experience of the Eye of Medicine\n",
      "The Indian Eye of Ayush Sharma is a powerful tool that has gained popularity in the Indian eye, and it has been used to enhance the overall experience of Ayush Sharma, a powerful tool that can be used to enhance the overall experience of the Indian Eye of Ayush Sharma\n",
      "The Indian Eye of Ayush Sharma is a powerful tool that can help to enhance the overall experience of the Indian Eye of Medicine, which can help to enhance the overall experience[EOS]\n"
     ]
    }
   ],
   "source": [
    "output_text = tokenizer.decode(generated_ids[2])\n",
    "print(\"Generated text:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_text = tokenizer.decode(generated_ids[3])\n",
    "# print(\"Generated text:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
